{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatjain2/machine_learning_6th_semester/blob/main/CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bf686e-0f37-487f-8588-c7af7e790fc9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "3a332865-d47e-4dd8-b8ac-eebdb9a2b55e"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dc3159-bc67-4d61-af45-0c91543b9986"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'0827CO191008_Assignment_Unit-1_Unit-2 _DBMS.gdoc'\n",
            "'0827CO191008_Quiz Assignment.docx'\n",
            " 1.css\n",
            " 20210915_145357.jpg\n",
            "'ADA Experiments List (1).gdoc'\n",
            "'ADA Experiments List.gdoc'\n",
            "'ADA Experiments List.pdf'\n",
            "'ADA Unit-4.gdoc'\n",
            "'ADA Unit-4.pdf'\n",
            " Akshat_Jain_Cybersecurity_Foundation_Student_Certificate.pdf\n",
            "'alexa skill quiz on marvel.jpg'\n",
            "'Blockchain and transforming world.gdoc'\n",
            "'Blockchain and transforming world.pdf'\n",
            "'C++ certificate SOLOLEARN.pdf'\n",
            "'Certificate Mycaptain Internship.pdf'\n",
            "'certificate of covid 19 pledge.jpg'\n",
            " Classroom\n",
            "'CO BATCH ERP LOGIN ID PASSWORD  (8).gsheet'\n",
            "'Colab Notebooks'\n",
            "'Compiler Design Assignment1 0827CO191008_Akshat_Jain.docx'\n",
            "'Confirmation Message.gdoc'\n",
            "'Covid 19 pledge akshat jain.docx'\n",
            "'CS-504(A) IWT All assmt'\n",
            "'CS-505 Linux Lab work'\n",
            " CSIT_logo_cropped.jpg\n",
            "'CSO Akshat jain.pdf'\n",
            "'DB Application Coursera.pdf'\n",
            " diabetes.csv\n",
            "'Fee receipt 3rd sem.pdf'\n",
            "'Format for Minor Project Synopsis.docx'\n",
            "'Fractional Knapsack.pdf'\n",
            "'Fundamental training'\n",
            "'Getting started.pdf'\n",
            "'GuviCertification - 961a474Hj01zrg99V1.png'\n",
            "'HackerRank Python certificate.png'\n",
            "'IBM PY0101EN Certificate _ edX.pdf'\n",
            " Java_Akshat_Jain_CO08.docx\n",
            "'Java final List of Experiment.docx'\n",
            "'LoA_Akshat Jain.pdf'\n",
            "'OS Class notes Unit-1 Dheeraj Shringi.gdoc'\n",
            " Parent_AFD_2292587_28122020123237527.pdf\n",
            " Python_certificate.jpg\n",
            "'Python Programming Experiment Lsit July Dec 2021 (1).gdoc'\n",
            "'Python Programming Experiment Lsit July Dec 2021.gdoc'\n",
            " Quick_Sort.docx\n",
            "'Quick sort.pdf'\n",
            " Quick_Sort.pdf\n",
            "'_.__ Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal __.PDF'\n",
            "'R Assignment 3 0827CO191008_Akshat_Jain.gdoc'\n",
            "'Screenshot 2021-04-26 120634.jpg'\n",
            " Screenshot_20210806-123312_Meet.jpg\n",
            "'Software Product Life Cycle (SDLC) skill development lab.gslides'\n",
            "'Student_AFD_2292587_28122020123237362 (1).pdf'\n",
            "'Student_AFD_2292587_28122020123237362 (2).pdf'\n",
            " Student_AFD_2292587_28122020123237362.pdf\n",
            "'Swachh Innovative Technology Challenge 2022.pdf'\n",
            "'Synopsis G1 - LIDMS.gdoc'\n",
            " TOC_Practical_assessment_0827CO191008.gdoc\n",
            "'Unit Test.gdoc'\n",
            "'Untitled spreadsheet.gsheet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "69e399cb-14b5-49e0-9db4-e83f4a9b684f"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb6357e-0bff-48fe-a27e-26d2c016289c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb6357e-0bff-48fe-a27e-26d2c016289c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bb6357e-0bff-48fe-a27e-26d2c016289c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bb6357e-0bff-48fe-a27e-26d2c016289c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "a6563046-b644-408c-c087-b6d1cbe22c16"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "706609da-0a4f-4067-9d5a-a4091bd71f43"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "caa32bfd-80b5-4c4b-df7d-762c1004d00a"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "0e8de308-167f-49a5-85c5-acbd29b57fdd"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "1e686a12-e76d-4e39-e66e-4060541bac67"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "6723d8a2-aed8-4f42-9a4f-2820962f0a8f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6e56a1-dff5-4522-ccc0-1b815d6ce81c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                216       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "03c35bcd-b979-43ec-81ae-ac74297f2df9"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=750, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.6293 - val_loss: 0.6605 - val_accuracy: 0.6260\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6576 - val_accuracy: 0.6260\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6680 - val_loss: 0.6450 - val_accuracy: 0.6260\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6680 - val_loss: 0.6405 - val_accuracy: 0.6260\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6660 - val_loss: 0.6199 - val_accuracy: 0.6504\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6701 - val_loss: 0.6075 - val_accuracy: 0.6585\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.6965 - val_loss: 0.5941 - val_accuracy: 0.6748\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7149 - val_loss: 0.5576 - val_accuracy: 0.6829\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7108 - val_loss: 0.5408 - val_accuracy: 0.7236\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7373 - val_loss: 0.5372 - val_accuracy: 0.7236\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7495 - val_loss: 0.5178 - val_accuracy: 0.7154\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7495 - val_loss: 0.5249 - val_accuracy: 0.7398\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7617 - val_loss: 0.5163 - val_accuracy: 0.7236\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7597 - val_loss: 0.4851 - val_accuracy: 0.7398\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7597 - val_loss: 0.5184 - val_accuracy: 0.7886\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7658 - val_loss: 0.4804 - val_accuracy: 0.7724\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7699 - val_loss: 0.4693 - val_accuracy: 0.7642\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7637 - val_loss: 0.4707 - val_accuracy: 0.7642\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7576 - val_loss: 0.4854 - val_accuracy: 0.7561\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7658 - val_loss: 0.4684 - val_accuracy: 0.7642\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7699 - val_loss: 0.4698 - val_accuracy: 0.7724\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7576 - val_loss: 0.4687 - val_accuracy: 0.7805\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7678 - val_loss: 0.4670 - val_accuracy: 0.7642\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7576 - val_loss: 0.4996 - val_accuracy: 0.7886\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7556 - val_loss: 0.4700 - val_accuracy: 0.7805\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7536 - val_loss: 0.4841 - val_accuracy: 0.7642\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7841 - val_loss: 0.4644 - val_accuracy: 0.7642\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7658 - val_loss: 0.4810 - val_accuracy: 0.8049\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7637 - val_loss: 0.4777 - val_accuracy: 0.7724\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7821 - val_loss: 0.4999 - val_accuracy: 0.7805\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7658 - val_loss: 0.4883 - val_accuracy: 0.8049\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7617 - val_loss: 0.4698 - val_accuracy: 0.7886\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7780 - val_loss: 0.4735 - val_accuracy: 0.7967\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7719 - val_loss: 0.4733 - val_accuracy: 0.7886\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7699 - val_loss: 0.4713 - val_accuracy: 0.7480\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.4698 - val_accuracy: 0.7886\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7637 - val_loss: 0.4628 - val_accuracy: 0.7805\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7800 - val_loss: 0.4726 - val_accuracy: 0.7561\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7617 - val_loss: 0.4632 - val_accuracy: 0.7886\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7699 - val_loss: 0.4688 - val_accuracy: 0.7886\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7678 - val_loss: 0.4685 - val_accuracy: 0.7805\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7617 - val_loss: 0.4950 - val_accuracy: 0.7642\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7576 - val_loss: 0.4655 - val_accuracy: 0.7886\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7862 - val_loss: 0.4697 - val_accuracy: 0.7724\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7637 - val_loss: 0.4825 - val_accuracy: 0.7886\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7617 - val_loss: 0.4769 - val_accuracy: 0.7886\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7658 - val_loss: 0.4634 - val_accuracy: 0.7886\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7739 - val_loss: 0.5032 - val_accuracy: 0.7642\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.4853 - val_accuracy: 0.7967\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7678 - val_loss: 0.4627 - val_accuracy: 0.7967\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7967\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7805\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.4676 - val_accuracy: 0.7886\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7515 - val_loss: 0.4697 - val_accuracy: 0.7886\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7739 - val_loss: 0.5061 - val_accuracy: 0.7561\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.4762 - val_accuracy: 0.7886\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7984 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7678 - val_loss: 0.4637 - val_accuracy: 0.8049\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.4733 - val_accuracy: 0.7805\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7800 - val_loss: 0.4868 - val_accuracy: 0.7724\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.4652 - val_accuracy: 0.8049\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7841 - val_loss: 0.4999 - val_accuracy: 0.7886\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7862 - val_loss: 0.4668 - val_accuracy: 0.7967\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7739 - val_loss: 0.4785 - val_accuracy: 0.7805\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7862 - val_loss: 0.4908 - val_accuracy: 0.7886\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7800 - val_loss: 0.4734 - val_accuracy: 0.7805\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7739 - val_loss: 0.4723 - val_accuracy: 0.7805\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7678 - val_loss: 0.4661 - val_accuracy: 0.8130\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7719 - val_loss: 0.4809 - val_accuracy: 0.7967\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7739 - val_loss: 0.4748 - val_accuracy: 0.7642\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7923 - val_loss: 0.4785 - val_accuracy: 0.7805\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7780 - val_loss: 0.5218 - val_accuracy: 0.7805\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7480\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7678 - val_loss: 0.5107 - val_accuracy: 0.7886\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.4816 - val_accuracy: 0.7724\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7637 - val_loss: 0.4930 - val_accuracy: 0.7886\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8045 - val_loss: 0.4870 - val_accuracy: 0.7967\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7800 - val_loss: 0.4691 - val_accuracy: 0.8049\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7800 - val_loss: 0.4663 - val_accuracy: 0.8130\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4745 - val_accuracy: 0.8130\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7821 - val_loss: 0.5114 - val_accuracy: 0.7805\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7821 - val_loss: 0.4836 - val_accuracy: 0.8130\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.4740 - val_accuracy: 0.7886\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7805\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4661 - val_accuracy: 0.7967\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7637 - val_loss: 0.5300 - val_accuracy: 0.7642\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7821 - val_loss: 0.4708 - val_accuracy: 0.7805\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7923 - val_loss: 0.4671 - val_accuracy: 0.7967\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7841 - val_loss: 0.4763 - val_accuracy: 0.7642\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7923 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7943 - val_loss: 0.4960 - val_accuracy: 0.7886\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7780 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7902 - val_loss: 0.5263 - val_accuracy: 0.7398\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7658 - val_loss: 0.4879 - val_accuracy: 0.7886\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7760 - val_loss: 0.4729 - val_accuracy: 0.8049\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7821 - val_loss: 0.4767 - val_accuracy: 0.7805\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7963 - val_loss: 0.4784 - val_accuracy: 0.7886\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7678 - val_loss: 0.4753 - val_accuracy: 0.7805\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7967\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8126 - val_loss: 0.4656 - val_accuracy: 0.8293\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7923 - val_loss: 0.4750 - val_accuracy: 0.7805\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7841 - val_loss: 0.4686 - val_accuracy: 0.8211\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7963 - val_loss: 0.5035 - val_accuracy: 0.7886\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7699 - val_loss: 0.4771 - val_accuracy: 0.7967\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7821 - val_loss: 0.4856 - val_accuracy: 0.7886\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7963 - val_loss: 0.5721 - val_accuracy: 0.7073\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7902 - val_loss: 0.4804 - val_accuracy: 0.7805\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7862 - val_loss: 0.4793 - val_accuracy: 0.7886\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8045 - val_loss: 0.5008 - val_accuracy: 0.7480\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7719 - val_loss: 0.4795 - val_accuracy: 0.7967\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7862 - val_loss: 0.4764 - val_accuracy: 0.7724\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7862 - val_loss: 0.4921 - val_accuracy: 0.7886\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7943 - val_loss: 0.4767 - val_accuracy: 0.8211\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7862 - val_loss: 0.4831 - val_accuracy: 0.8049\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7902 - val_loss: 0.4993 - val_accuracy: 0.7642\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7821 - val_loss: 0.4830 - val_accuracy: 0.8211\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7943 - val_loss: 0.4892 - val_accuracy: 0.7724\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7984 - val_loss: 0.4801 - val_accuracy: 0.7886\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7642\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7841 - val_loss: 0.4876 - val_accuracy: 0.7561\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.4793 - val_accuracy: 0.7886\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7862 - val_loss: 0.4853 - val_accuracy: 0.8130\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7800 - val_loss: 0.4853 - val_accuracy: 0.7805\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7963 - val_loss: 0.4964 - val_accuracy: 0.7724\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7963 - val_loss: 0.4752 - val_accuracy: 0.7967\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8106 - val_loss: 0.4837 - val_accuracy: 0.7724\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7821 - val_loss: 0.5113 - val_accuracy: 0.7561\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8187 - val_loss: 0.4849 - val_accuracy: 0.7886\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8004 - val_loss: 0.5736 - val_accuracy: 0.7561\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7923 - val_loss: 0.4808 - val_accuracy: 0.7886\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7984 - val_loss: 0.4924 - val_accuracy: 0.7886\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8147 - val_loss: 0.5366 - val_accuracy: 0.7724\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8024 - val_loss: 0.4915 - val_accuracy: 0.7805\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7862 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8024 - val_loss: 0.5422 - val_accuracy: 0.7317\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7984 - val_loss: 0.4853 - val_accuracy: 0.7967\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7943 - val_loss: 0.4851 - val_accuracy: 0.8130\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8045 - val_loss: 0.4882 - val_accuracy: 0.7967\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7800 - val_loss: 0.4938 - val_accuracy: 0.7805\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8004 - val_loss: 0.5043 - val_accuracy: 0.7724\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7943 - val_loss: 0.4835 - val_accuracy: 0.8130\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8045 - val_loss: 0.5241 - val_accuracy: 0.7398\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8024 - val_loss: 0.5025 - val_accuracy: 0.7642\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8004 - val_loss: 0.5082 - val_accuracy: 0.7642\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8106 - val_loss: 0.4779 - val_accuracy: 0.8049\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7984 - val_loss: 0.4892 - val_accuracy: 0.7805\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8024 - val_loss: 0.4993 - val_accuracy: 0.7724\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7984 - val_loss: 0.4773 - val_accuracy: 0.7967\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8004 - val_loss: 0.5344 - val_accuracy: 0.7480\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7841 - val_loss: 0.5317 - val_accuracy: 0.7642\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7963 - val_loss: 0.4987 - val_accuracy: 0.7724\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8004 - val_loss: 0.5264 - val_accuracy: 0.7480\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.7963 - val_loss: 0.4941 - val_accuracy: 0.7642\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8065 - val_loss: 0.4878 - val_accuracy: 0.7805\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8045 - val_loss: 0.4848 - val_accuracy: 0.7886\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8024 - val_loss: 0.5157 - val_accuracy: 0.7805\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8147 - val_loss: 0.5338 - val_accuracy: 0.7561\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8106 - val_loss: 0.5032 - val_accuracy: 0.7642\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8228 - val_loss: 0.5033 - val_accuracy: 0.7886\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8106 - val_loss: 0.4927 - val_accuracy: 0.7724\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.7984 - val_loss: 0.4946 - val_accuracy: 0.7805\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8024 - val_loss: 0.5044 - val_accuracy: 0.7805\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8147 - val_loss: 0.5168 - val_accuracy: 0.7805\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8086 - val_loss: 0.4954 - val_accuracy: 0.7886\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8126 - val_loss: 0.4990 - val_accuracy: 0.7805\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7963 - val_loss: 0.5244 - val_accuracy: 0.7724\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8086 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.7923 - val_loss: 0.4971 - val_accuracy: 0.7724\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8289 - val_loss: 0.6302 - val_accuracy: 0.6911\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8106 - val_loss: 0.5025 - val_accuracy: 0.7724\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8126 - val_loss: 0.5135 - val_accuracy: 0.7561\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8024 - val_loss: 0.4899 - val_accuracy: 0.7967\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.7984 - val_loss: 0.5020 - val_accuracy: 0.7724\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8004 - val_loss: 0.5070 - val_accuracy: 0.7967\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.7923 - val_loss: 0.5289 - val_accuracy: 0.7317\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8147 - val_loss: 0.5065 - val_accuracy: 0.7642\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8086 - val_loss: 0.5121 - val_accuracy: 0.7642\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8147 - val_loss: 0.5755 - val_accuracy: 0.7561\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8269 - val_loss: 0.5110 - val_accuracy: 0.7805\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8126 - val_loss: 0.5026 - val_accuracy: 0.7967\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8106 - val_loss: 0.5018 - val_accuracy: 0.7805\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8208 - val_loss: 0.5160 - val_accuracy: 0.7805\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8208 - val_loss: 0.5148 - val_accuracy: 0.7480\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8208 - val_loss: 0.4860 - val_accuracy: 0.8374\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8126 - val_loss: 0.5031 - val_accuracy: 0.8049\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.7902 - val_loss: 0.5111 - val_accuracy: 0.7724\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8004 - val_loss: 0.5127 - val_accuracy: 0.7805\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8167 - val_loss: 0.5216 - val_accuracy: 0.7724\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8106 - val_loss: 0.4890 - val_accuracy: 0.8049\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8106 - val_loss: 0.5034 - val_accuracy: 0.7642\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8269 - val_loss: 0.5149 - val_accuracy: 0.7561\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8228 - val_loss: 0.5236 - val_accuracy: 0.7805\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8147 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8167 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8024 - val_loss: 0.4905 - val_accuracy: 0.8049\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8167 - val_loss: 0.4999 - val_accuracy: 0.7967\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8187 - val_loss: 0.5129 - val_accuracy: 0.8049\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8106 - val_loss: 0.5232 - val_accuracy: 0.7642\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8187 - val_loss: 0.4994 - val_accuracy: 0.7805\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8024 - val_loss: 0.5343 - val_accuracy: 0.7642\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8126 - val_loss: 0.5063 - val_accuracy: 0.7642\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8167 - val_loss: 0.5098 - val_accuracy: 0.7967\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8086 - val_loss: 0.5023 - val_accuracy: 0.7805\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8126 - val_loss: 0.5300 - val_accuracy: 0.7724\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8269 - val_loss: 0.5002 - val_accuracy: 0.8130\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8167 - val_loss: 0.5012 - val_accuracy: 0.7967\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8208 - val_loss: 0.5158 - val_accuracy: 0.7886\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8228 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8045 - val_loss: 0.5123 - val_accuracy: 0.7805\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8167 - val_loss: 0.5105 - val_accuracy: 0.7967\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8086 - val_loss: 0.5261 - val_accuracy: 0.7642\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8391 - val_loss: 0.5676 - val_accuracy: 0.7480\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8126 - val_loss: 0.5790 - val_accuracy: 0.7317\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8147 - val_loss: 0.4992 - val_accuracy: 0.7886\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8228 - val_loss: 0.5281 - val_accuracy: 0.7724\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8167 - val_loss: 0.5536 - val_accuracy: 0.7480\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8187 - val_loss: 0.5257 - val_accuracy: 0.7805\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8269 - val_loss: 0.5415 - val_accuracy: 0.7642\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8248 - val_loss: 0.5301 - val_accuracy: 0.7724\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8289 - val_loss: 0.5232 - val_accuracy: 0.7724\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8208 - val_loss: 0.5242 - val_accuracy: 0.7642\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8452 - val_loss: 0.5209 - val_accuracy: 0.7886\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8310 - val_loss: 0.5407 - val_accuracy: 0.7561\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8289 - val_loss: 0.5177 - val_accuracy: 0.7642\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8045 - val_loss: 0.5107 - val_accuracy: 0.7967\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8228 - val_loss: 0.5512 - val_accuracy: 0.7561\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8187 - val_loss: 0.5128 - val_accuracy: 0.8130\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8350 - val_loss: 0.5411 - val_accuracy: 0.7724\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8228 - val_loss: 0.5443 - val_accuracy: 0.7480\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8208 - val_loss: 0.5398 - val_accuracy: 0.7724\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8350 - val_loss: 0.5019 - val_accuracy: 0.8049\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8228 - val_loss: 0.5124 - val_accuracy: 0.7967\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8310 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8187 - val_loss: 0.5287 - val_accuracy: 0.7805\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8350 - val_loss: 0.5193 - val_accuracy: 0.7886\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8269 - val_loss: 0.5311 - val_accuracy: 0.7805\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8310 - val_loss: 0.5410 - val_accuracy: 0.7805\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8228 - val_loss: 0.5701 - val_accuracy: 0.7480\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8228 - val_loss: 0.5261 - val_accuracy: 0.7886\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8473 - val_loss: 0.5394 - val_accuracy: 0.7480\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8330 - val_loss: 0.5144 - val_accuracy: 0.7561\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8371 - val_loss: 0.5169 - val_accuracy: 0.7886\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8391 - val_loss: 0.5598 - val_accuracy: 0.7805\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8310 - val_loss: 0.5116 - val_accuracy: 0.7967\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8289 - val_loss: 0.5207 - val_accuracy: 0.7805\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8330 - val_loss: 0.5566 - val_accuracy: 0.7480\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8269 - val_loss: 0.5444 - val_accuracy: 0.7724\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8391 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8371 - val_loss: 0.5627 - val_accuracy: 0.7480\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8350 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8432 - val_loss: 0.5574 - val_accuracy: 0.7724\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8371 - val_loss: 0.5132 - val_accuracy: 0.7967\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8330 - val_loss: 0.5730 - val_accuracy: 0.7154\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8473 - val_loss: 0.5194 - val_accuracy: 0.8049\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8391 - val_loss: 0.5581 - val_accuracy: 0.7561\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8391 - val_loss: 0.5249 - val_accuracy: 0.7805\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8248 - val_loss: 0.5443 - val_accuracy: 0.7724\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8473 - val_loss: 0.5414 - val_accuracy: 0.7480\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8208 - val_loss: 0.5588 - val_accuracy: 0.7724\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8391 - val_loss: 0.5530 - val_accuracy: 0.7724\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8371 - val_loss: 0.5239 - val_accuracy: 0.7724\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8248 - val_loss: 0.5501 - val_accuracy: 0.7724\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8371 - val_loss: 0.5366 - val_accuracy: 0.7642\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8391 - val_loss: 0.5187 - val_accuracy: 0.7886\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8432 - val_loss: 0.5059 - val_accuracy: 0.8130\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8513 - val_loss: 0.5773 - val_accuracy: 0.7480\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8228 - val_loss: 0.5731 - val_accuracy: 0.7724\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8289 - val_loss: 0.5142 - val_accuracy: 0.7967\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8432 - val_loss: 0.6039 - val_accuracy: 0.7236\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8350 - val_loss: 0.5472 - val_accuracy: 0.7561\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8452 - val_loss: 0.5617 - val_accuracy: 0.7642\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8473 - val_loss: 0.5605 - val_accuracy: 0.7398\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8371 - val_loss: 0.6252 - val_accuracy: 0.7236\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8289 - val_loss: 0.5281 - val_accuracy: 0.7805\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8350 - val_loss: 0.5530 - val_accuracy: 0.7480\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8350 - val_loss: 0.5415 - val_accuracy: 0.7886\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8289 - val_loss: 0.5298 - val_accuracy: 0.7642\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8493 - val_loss: 0.5409 - val_accuracy: 0.7805\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8391 - val_loss: 0.5763 - val_accuracy: 0.7642\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8391 - val_loss: 0.5323 - val_accuracy: 0.7886\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8473 - val_loss: 0.5647 - val_accuracy: 0.7073\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8432 - val_loss: 0.5363 - val_accuracy: 0.7886\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8310 - val_loss: 0.5406 - val_accuracy: 0.7480\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8432 - val_loss: 0.5436 - val_accuracy: 0.7724\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8391 - val_loss: 0.5002 - val_accuracy: 0.8130\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8371 - val_loss: 0.5840 - val_accuracy: 0.7480\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8452 - val_loss: 0.5588 - val_accuracy: 0.7642\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8371 - val_loss: 0.5666 - val_accuracy: 0.7398\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8432 - val_loss: 0.5663 - val_accuracy: 0.7398\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8432 - val_loss: 0.6170 - val_accuracy: 0.7154\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8595 - val_loss: 0.5288 - val_accuracy: 0.8130\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8513 - val_loss: 0.5553 - val_accuracy: 0.7480\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8411 - val_loss: 0.5272 - val_accuracy: 0.8130\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8615 - val_loss: 0.5722 - val_accuracy: 0.7317\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8452 - val_loss: 0.5863 - val_accuracy: 0.7561\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8493 - val_loss: 0.6281 - val_accuracy: 0.7154\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8452 - val_loss: 0.6152 - val_accuracy: 0.7561\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8554 - val_loss: 0.5636 - val_accuracy: 0.7398\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8391 - val_loss: 0.5256 - val_accuracy: 0.7967\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8574 - val_loss: 0.5625 - val_accuracy: 0.7805\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8554 - val_loss: 0.5482 - val_accuracy: 0.7805\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8473 - val_loss: 0.5953 - val_accuracy: 0.7480\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8350 - val_loss: 0.5456 - val_accuracy: 0.7561\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8635 - val_loss: 0.5893 - val_accuracy: 0.7561\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8534 - val_loss: 0.5476 - val_accuracy: 0.7724\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8574 - val_loss: 0.7175 - val_accuracy: 0.6585\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8350 - val_loss: 0.5374 - val_accuracy: 0.7724\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8391 - val_loss: 0.5513 - val_accuracy: 0.7967\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8391 - val_loss: 0.5527 - val_accuracy: 0.7805\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8432 - val_loss: 0.5407 - val_accuracy: 0.7805\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8432 - val_loss: 0.5597 - val_accuracy: 0.7724\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8513 - val_loss: 0.5884 - val_accuracy: 0.7642\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8473 - val_loss: 0.5977 - val_accuracy: 0.7480\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8411 - val_loss: 0.5519 - val_accuracy: 0.7724\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8513 - val_loss: 0.5549 - val_accuracy: 0.7642\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8493 - val_loss: 0.5071 - val_accuracy: 0.7967\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8513 - val_loss: 0.5717 - val_accuracy: 0.7886\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8717 - val_loss: 0.5131 - val_accuracy: 0.8211\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8391 - val_loss: 0.6598 - val_accuracy: 0.7317\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8452 - val_loss: 0.5578 - val_accuracy: 0.7805\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8534 - val_loss: 0.5681 - val_accuracy: 0.7480\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8534 - val_loss: 0.5493 - val_accuracy: 0.7724\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8493 - val_loss: 0.5862 - val_accuracy: 0.7642\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8452 - val_loss: 0.6145 - val_accuracy: 0.7561\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8676 - val_loss: 0.6110 - val_accuracy: 0.7398\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8615 - val_loss: 0.5715 - val_accuracy: 0.7154\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8513 - val_loss: 0.6174 - val_accuracy: 0.7398\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8635 - val_loss: 0.6080 - val_accuracy: 0.7398\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8473 - val_loss: 0.6046 - val_accuracy: 0.7480\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8493 - val_loss: 0.5402 - val_accuracy: 0.7724\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8635 - val_loss: 0.5416 - val_accuracy: 0.7724\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8574 - val_loss: 0.5782 - val_accuracy: 0.7398\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8432 - val_loss: 0.5593 - val_accuracy: 0.7561\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8513 - val_loss: 0.5549 - val_accuracy: 0.7886\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8635 - val_loss: 0.5467 - val_accuracy: 0.7724\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8595 - val_loss: 0.5760 - val_accuracy: 0.7480\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8534 - val_loss: 0.5728 - val_accuracy: 0.7317\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8371 - val_loss: 0.5604 - val_accuracy: 0.7642\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8473 - val_loss: 0.5865 - val_accuracy: 0.7561\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8289 - val_loss: 0.5398 - val_accuracy: 0.7480\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8411 - val_loss: 0.6017 - val_accuracy: 0.7398\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8452 - val_loss: 0.5691 - val_accuracy: 0.7642\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8574 - val_loss: 0.5339 - val_accuracy: 0.7398\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8513 - val_loss: 0.5379 - val_accuracy: 0.7886\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8513 - val_loss: 0.5585 - val_accuracy: 0.7724\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8656 - val_loss: 0.5684 - val_accuracy: 0.7561\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8534 - val_loss: 0.5624 - val_accuracy: 0.7805\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8554 - val_loss: 0.5725 - val_accuracy: 0.7480\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8615 - val_loss: 0.5498 - val_accuracy: 0.7805\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8452 - val_loss: 0.5499 - val_accuracy: 0.7642\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8493 - val_loss: 0.5866 - val_accuracy: 0.7317\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8432 - val_loss: 0.5776 - val_accuracy: 0.7480\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8534 - val_loss: 0.5201 - val_accuracy: 0.7967\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8411 - val_loss: 0.5663 - val_accuracy: 0.7398\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8473 - val_loss: 0.5668 - val_accuracy: 0.7642\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8615 - val_loss: 0.6859 - val_accuracy: 0.7154\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8391 - val_loss: 0.5608 - val_accuracy: 0.7642\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8656 - val_loss: 0.5867 - val_accuracy: 0.7561\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8513 - val_loss: 0.5708 - val_accuracy: 0.7317\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8513 - val_loss: 0.5622 - val_accuracy: 0.7480\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8554 - val_loss: 0.5224 - val_accuracy: 0.7886\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8534 - val_loss: 0.5648 - val_accuracy: 0.7642\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8350 - val_loss: 0.5399 - val_accuracy: 0.8049\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8635 - val_loss: 0.5476 - val_accuracy: 0.7398\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8513 - val_loss: 0.5499 - val_accuracy: 0.7886\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8595 - val_loss: 0.6109 - val_accuracy: 0.7480\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8574 - val_loss: 0.8173 - val_accuracy: 0.7073\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8615 - val_loss: 0.5804 - val_accuracy: 0.7154\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8758 - val_loss: 0.5244 - val_accuracy: 0.7886\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8574 - val_loss: 0.6372 - val_accuracy: 0.7236\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8635 - val_loss: 0.5346 - val_accuracy: 0.7642\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8697 - val_loss: 0.5769 - val_accuracy: 0.7317\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8615 - val_loss: 0.6867 - val_accuracy: 0.7480\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8411 - val_loss: 0.6390 - val_accuracy: 0.7317\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8615 - val_loss: 0.6081 - val_accuracy: 0.7236\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8574 - val_loss: 0.6255 - val_accuracy: 0.7317\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8595 - val_loss: 0.6596 - val_accuracy: 0.7317\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8595 - val_loss: 0.5320 - val_accuracy: 0.7561\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8493 - val_loss: 0.5575 - val_accuracy: 0.7561\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8615 - val_loss: 0.6012 - val_accuracy: 0.7398\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8534 - val_loss: 0.5954 - val_accuracy: 0.7561\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8676 - val_loss: 0.5894 - val_accuracy: 0.7642\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8635 - val_loss: 0.5922 - val_accuracy: 0.7480\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8554 - val_loss: 0.5731 - val_accuracy: 0.7561\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8493 - val_loss: 0.6326 - val_accuracy: 0.7154\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8656 - val_loss: 0.5856 - val_accuracy: 0.7805\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8534 - val_loss: 0.5727 - val_accuracy: 0.7561\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8676 - val_loss: 0.5531 - val_accuracy: 0.7886\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8635 - val_loss: 0.5921 - val_accuracy: 0.7398\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8554 - val_loss: 0.5548 - val_accuracy: 0.7642\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8656 - val_loss: 0.5560 - val_accuracy: 0.7642\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8595 - val_loss: 0.6460 - val_accuracy: 0.7480\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8595 - val_loss: 0.6501 - val_accuracy: 0.7236\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8839 - val_loss: 0.6082 - val_accuracy: 0.7561\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8574 - val_loss: 0.6083 - val_accuracy: 0.7561\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8432 - val_loss: 0.5792 - val_accuracy: 0.7642\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8615 - val_loss: 0.6058 - val_accuracy: 0.7236\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8635 - val_loss: 0.6463 - val_accuracy: 0.7317\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8595 - val_loss: 0.5691 - val_accuracy: 0.7480\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8717 - val_loss: 0.6456 - val_accuracy: 0.7398\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8554 - val_loss: 0.7145 - val_accuracy: 0.6992\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8819 - val_loss: 0.6392 - val_accuracy: 0.7317\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8615 - val_loss: 0.6827 - val_accuracy: 0.7236\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8798 - val_loss: 0.6424 - val_accuracy: 0.7317\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8656 - val_loss: 0.5683 - val_accuracy: 0.7724\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8717 - val_loss: 0.5939 - val_accuracy: 0.7724\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8778 - val_loss: 0.6429 - val_accuracy: 0.7236\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8554 - val_loss: 0.6156 - val_accuracy: 0.7398\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8615 - val_loss: 0.5705 - val_accuracy: 0.7724\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8656 - val_loss: 0.5869 - val_accuracy: 0.7561\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8758 - val_loss: 0.5635 - val_accuracy: 0.7561\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8717 - val_loss: 0.6121 - val_accuracy: 0.7642\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8656 - val_loss: 0.6874 - val_accuracy: 0.7236\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8778 - val_loss: 0.5926 - val_accuracy: 0.7561\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8737 - val_loss: 0.6865 - val_accuracy: 0.7398\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8615 - val_loss: 0.5270 - val_accuracy: 0.7805\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8595 - val_loss: 0.6027 - val_accuracy: 0.7642\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8554 - val_loss: 0.6211 - val_accuracy: 0.7561\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8758 - val_loss: 0.6563 - val_accuracy: 0.7480\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8595 - val_loss: 0.6062 - val_accuracy: 0.7317\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8819 - val_loss: 0.5854 - val_accuracy: 0.7398\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8615 - val_loss: 0.6177 - val_accuracy: 0.7561\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8635 - val_loss: 0.6784 - val_accuracy: 0.7317\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8697 - val_loss: 0.6187 - val_accuracy: 0.7642\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8859 - val_loss: 0.5642 - val_accuracy: 0.7642\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8697 - val_loss: 0.6787 - val_accuracy: 0.7561\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8615 - val_loss: 0.6819 - val_accuracy: 0.7236\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8554 - val_loss: 0.6507 - val_accuracy: 0.7317\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8717 - val_loss: 0.6558 - val_accuracy: 0.7154\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8758 - val_loss: 0.6160 - val_accuracy: 0.7561\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8635 - val_loss: 0.6842 - val_accuracy: 0.7317\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8656 - val_loss: 0.6091 - val_accuracy: 0.7561\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8697 - val_loss: 0.6433 - val_accuracy: 0.7561\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8819 - val_loss: 0.6436 - val_accuracy: 0.7398\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8778 - val_loss: 0.5800 - val_accuracy: 0.7561\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8656 - val_loss: 0.6251 - val_accuracy: 0.7398\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8676 - val_loss: 0.5944 - val_accuracy: 0.7642\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8676 - val_loss: 0.6363 - val_accuracy: 0.7480\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8635 - val_loss: 0.6545 - val_accuracy: 0.7398\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8656 - val_loss: 0.6993 - val_accuracy: 0.7317\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8656 - val_loss: 0.5949 - val_accuracy: 0.7480\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8758 - val_loss: 0.5757 - val_accuracy: 0.7805\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8737 - val_loss: 0.6986 - val_accuracy: 0.7724\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8697 - val_loss: 0.6147 - val_accuracy: 0.7642\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8737 - val_loss: 0.6403 - val_accuracy: 0.7317\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8839 - val_loss: 0.6818 - val_accuracy: 0.7236\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8697 - val_loss: 0.6477 - val_accuracy: 0.7398\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8737 - val_loss: 0.6150 - val_accuracy: 0.7642\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8676 - val_loss: 0.6028 - val_accuracy: 0.7724\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8778 - val_loss: 0.6653 - val_accuracy: 0.7317\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8717 - val_loss: 0.7493 - val_accuracy: 0.7236\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8941 - val_loss: 0.6941 - val_accuracy: 0.7317\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8615 - val_loss: 0.6781 - val_accuracy: 0.7154\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8615 - val_loss: 0.7506 - val_accuracy: 0.7154\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8819 - val_loss: 0.7039 - val_accuracy: 0.7154\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8921 - val_loss: 0.6898 - val_accuracy: 0.7398\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8697 - val_loss: 0.6289 - val_accuracy: 0.7480\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8697 - val_loss: 0.6543 - val_accuracy: 0.7642\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.8697 - val_loss: 0.6918 - val_accuracy: 0.7480\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8859 - val_loss: 0.5655 - val_accuracy: 0.7724\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8880 - val_loss: 0.6773 - val_accuracy: 0.7480\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8676 - val_loss: 0.6486 - val_accuracy: 0.7480\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8839 - val_loss: 0.6534 - val_accuracy: 0.7398\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8717 - val_loss: 0.6336 - val_accuracy: 0.7398\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8819 - val_loss: 0.7042 - val_accuracy: 0.7398\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8921 - val_loss: 0.7570 - val_accuracy: 0.7398\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8921 - val_loss: 0.6249 - val_accuracy: 0.7236\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8778 - val_loss: 0.6809 - val_accuracy: 0.7154\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8961 - val_loss: 0.6738 - val_accuracy: 0.7236\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8758 - val_loss: 0.6592 - val_accuracy: 0.7642\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.8717 - val_loss: 0.6956 - val_accuracy: 0.7073\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8921 - val_loss: 0.6067 - val_accuracy: 0.7642\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8798 - val_loss: 0.6806 - val_accuracy: 0.7480\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8941 - val_loss: 0.7198 - val_accuracy: 0.7073\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8880 - val_loss: 0.6783 - val_accuracy: 0.7317\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8758 - val_loss: 0.7160 - val_accuracy: 0.7154\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8615 - val_loss: 0.7235 - val_accuracy: 0.7236\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8819 - val_loss: 0.7455 - val_accuracy: 0.6992\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8737 - val_loss: 0.6615 - val_accuracy: 0.7642\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8737 - val_loss: 0.7028 - val_accuracy: 0.7073\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8737 - val_loss: 0.6667 - val_accuracy: 0.7236\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8880 - val_loss: 0.6865 - val_accuracy: 0.7236\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8819 - val_loss: 0.7548 - val_accuracy: 0.7561\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.8717 - val_loss: 0.7158 - val_accuracy: 0.7480\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8819 - val_loss: 0.7364 - val_accuracy: 0.7236\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8737 - val_loss: 0.5876 - val_accuracy: 0.7642\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8798 - val_loss: 0.6433 - val_accuracy: 0.7642\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8717 - val_loss: 0.6926 - val_accuracy: 0.7480\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8900 - val_loss: 0.7331 - val_accuracy: 0.7073\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8778 - val_loss: 0.6196 - val_accuracy: 0.7480\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8839 - val_loss: 0.6468 - val_accuracy: 0.7480\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8961 - val_loss: 0.8184 - val_accuracy: 0.6585\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8961 - val_loss: 0.7595 - val_accuracy: 0.7154\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8900 - val_loss: 0.6982 - val_accuracy: 0.6992\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8798 - val_loss: 0.6423 - val_accuracy: 0.7480\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8819 - val_loss: 0.6155 - val_accuracy: 0.7642\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8921 - val_loss: 0.7425 - val_accuracy: 0.7724\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8758 - val_loss: 0.6224 - val_accuracy: 0.7724\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8921 - val_loss: 0.6581 - val_accuracy: 0.7398\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8697 - val_loss: 0.6242 - val_accuracy: 0.7642\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8859 - val_loss: 0.7094 - val_accuracy: 0.7480\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8819 - val_loss: 0.6686 - val_accuracy: 0.7480\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8656 - val_loss: 0.6641 - val_accuracy: 0.7398\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8839 - val_loss: 0.7244 - val_accuracy: 0.7317\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.9002 - val_loss: 0.6728 - val_accuracy: 0.7805\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8676 - val_loss: 0.7255 - val_accuracy: 0.7398\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8839 - val_loss: 0.6317 - val_accuracy: 0.7398\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8839 - val_loss: 0.7806 - val_accuracy: 0.7236\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8737 - val_loss: 0.7530 - val_accuracy: 0.7154\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8798 - val_loss: 0.6796 - val_accuracy: 0.7480\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9002 - val_loss: 0.6416 - val_accuracy: 0.7724\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8737 - val_loss: 0.6922 - val_accuracy: 0.7561\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9022 - val_loss: 0.7666 - val_accuracy: 0.7073\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8737 - val_loss: 0.8364 - val_accuracy: 0.6992\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8921 - val_loss: 0.7378 - val_accuracy: 0.7317\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8839 - val_loss: 0.7464 - val_accuracy: 0.7154\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8859 - val_loss: 0.7228 - val_accuracy: 0.7236\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8921 - val_loss: 0.8147 - val_accuracy: 0.7154\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8982 - val_loss: 0.7741 - val_accuracy: 0.7236\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8961 - val_loss: 0.7914 - val_accuracy: 0.7236\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8819 - val_loss: 0.7862 - val_accuracy: 0.7154\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8819 - val_loss: 0.9388 - val_accuracy: 0.7236\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8921 - val_loss: 0.7713 - val_accuracy: 0.7398\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9002 - val_loss: 0.7534 - val_accuracy: 0.7073\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9002 - val_loss: 0.7878 - val_accuracy: 0.7154\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8819 - val_loss: 0.7395 - val_accuracy: 0.7236\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8921 - val_loss: 0.7427 - val_accuracy: 0.7236\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8900 - val_loss: 0.7429 - val_accuracy: 0.7236\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8961 - val_loss: 0.9125 - val_accuracy: 0.6992\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8921 - val_loss: 0.6174 - val_accuracy: 0.7398\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8880 - val_loss: 0.6842 - val_accuracy: 0.7398\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.8961 - val_loss: 0.6841 - val_accuracy: 0.7642\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9002 - val_loss: 0.8226 - val_accuracy: 0.7154\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8880 - val_loss: 0.7166 - val_accuracy: 0.7561\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8900 - val_loss: 0.7219 - val_accuracy: 0.7317\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8839 - val_loss: 0.7780 - val_accuracy: 0.7236\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8880 - val_loss: 0.7989 - val_accuracy: 0.7154\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.8921 - val_loss: 0.7374 - val_accuracy: 0.7480\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.8961 - val_loss: 0.8197 - val_accuracy: 0.7398\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8941 - val_loss: 0.8263 - val_accuracy: 0.7154\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8961 - val_loss: 0.7339 - val_accuracy: 0.7561\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8880 - val_loss: 0.7862 - val_accuracy: 0.7236\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.8921 - val_loss: 0.7326 - val_accuracy: 0.7398\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9002 - val_loss: 0.7968 - val_accuracy: 0.7154\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8900 - val_loss: 0.7350 - val_accuracy: 0.7236\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8900 - val_loss: 0.6685 - val_accuracy: 0.7561\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8819 - val_loss: 0.8380 - val_accuracy: 0.7154\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9185 - val_loss: 0.8051 - val_accuracy: 0.6748\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8900 - val_loss: 0.8224 - val_accuracy: 0.7317\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.8982 - val_loss: 0.8203 - val_accuracy: 0.7317\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8859 - val_loss: 0.7323 - val_accuracy: 0.7480\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8900 - val_loss: 0.6795 - val_accuracy: 0.7561\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8798 - val_loss: 0.9427 - val_accuracy: 0.6667\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8839 - val_loss: 0.7695 - val_accuracy: 0.7317\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8941 - val_loss: 1.0611 - val_accuracy: 0.6667\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.8859 - val_loss: 0.7234 - val_accuracy: 0.7317\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.8921 - val_loss: 1.1380 - val_accuracy: 0.6341\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9002 - val_loss: 0.8189 - val_accuracy: 0.7154\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.8839 - val_loss: 0.9815 - val_accuracy: 0.6911\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8900 - val_loss: 0.7658 - val_accuracy: 0.7317\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8839 - val_loss: 1.0698 - val_accuracy: 0.6667\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8880 - val_loss: 0.7511 - val_accuracy: 0.7317\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.8880 - val_loss: 0.7497 - val_accuracy: 0.7398\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.8778 - val_loss: 0.8111 - val_accuracy: 0.7480\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9002 - val_loss: 0.8472 - val_accuracy: 0.7154\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.8900 - val_loss: 0.8078 - val_accuracy: 0.7236\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8737 - val_loss: 0.7883 - val_accuracy: 0.7317\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9084 - val_loss: 0.7420 - val_accuracy: 0.7480\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.8941 - val_loss: 0.9150 - val_accuracy: 0.6829\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.8900 - val_loss: 0.8966 - val_accuracy: 0.7154\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.8798 - val_loss: 0.7131 - val_accuracy: 0.7480\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.8839 - val_loss: 1.0673 - val_accuracy: 0.6911\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8758 - val_loss: 0.8898 - val_accuracy: 0.7073\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.8941 - val_loss: 0.8569 - val_accuracy: 0.7236\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9104 - val_loss: 0.9122 - val_accuracy: 0.7317\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8859 - val_loss: 0.8183 - val_accuracy: 0.7236\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9002 - val_loss: 0.7636 - val_accuracy: 0.7317\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9124 - val_loss: 0.7267 - val_accuracy: 0.7317\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.8859 - val_loss: 0.7902 - val_accuracy: 0.7154\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9063 - val_loss: 0.8522 - val_accuracy: 0.7398\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.8982 - val_loss: 0.8268 - val_accuracy: 0.7398\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9002 - val_loss: 0.7101 - val_accuracy: 0.7561\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9022 - val_loss: 0.7498 - val_accuracy: 0.7236\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.8982 - val_loss: 0.7568 - val_accuracy: 0.7317\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9084 - val_loss: 0.8104 - val_accuracy: 0.7236\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9002 - val_loss: 0.8140 - val_accuracy: 0.7317\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.8819 - val_loss: 0.9076 - val_accuracy: 0.7236\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9063 - val_loss: 0.8873 - val_accuracy: 0.7154\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9084 - val_loss: 0.8239 - val_accuracy: 0.7317\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9043 - val_loss: 0.8043 - val_accuracy: 0.7398\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9145 - val_loss: 0.8680 - val_accuracy: 0.7236\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9063 - val_loss: 0.7700 - val_accuracy: 0.7480\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.9022 - val_loss: 0.7298 - val_accuracy: 0.7480\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.8982 - val_loss: 0.8323 - val_accuracy: 0.7398\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8921 - val_loss: 0.9798 - val_accuracy: 0.6992\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8921 - val_loss: 0.7083 - val_accuracy: 0.7561\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8961 - val_loss: 0.9498 - val_accuracy: 0.7073\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9104 - val_loss: 0.8134 - val_accuracy: 0.7236\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8921 - val_loss: 0.8292 - val_accuracy: 0.7236\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9022 - val_loss: 0.8822 - val_accuracy: 0.7073\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.8941 - val_loss: 0.8455 - val_accuracy: 0.6992\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.8982 - val_loss: 0.8024 - val_accuracy: 0.7317\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9002 - val_loss: 0.7878 - val_accuracy: 0.7154\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.8961 - val_loss: 0.8172 - val_accuracy: 0.7236\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9063 - val_loss: 0.9076 - val_accuracy: 0.6829\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8900 - val_loss: 0.8552 - val_accuracy: 0.7236\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9043 - val_loss: 0.8815 - val_accuracy: 0.7073\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9063 - val_loss: 0.8439 - val_accuracy: 0.7154\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9206 - val_loss: 0.8305 - val_accuracy: 0.7154\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9043 - val_loss: 0.7953 - val_accuracy: 0.7317\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9104 - val_loss: 0.7924 - val_accuracy: 0.7561\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9063 - val_loss: 0.7821 - val_accuracy: 0.7561\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8839 - val_loss: 1.0295 - val_accuracy: 0.7073\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8615 - val_loss: 0.7738 - val_accuracy: 0.7480\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9124 - val_loss: 0.8293 - val_accuracy: 0.7154\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9145 - val_loss: 0.7571 - val_accuracy: 0.7480\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8819 - val_loss: 0.8787 - val_accuracy: 0.7236\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9043 - val_loss: 0.7706 - val_accuracy: 0.7398\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9022 - val_loss: 0.7107 - val_accuracy: 0.7642\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9104 - val_loss: 0.8394 - val_accuracy: 0.7317\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9104 - val_loss: 0.8686 - val_accuracy: 0.7154\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9185 - val_loss: 0.8238 - val_accuracy: 0.7642\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9022 - val_loss: 0.8876 - val_accuracy: 0.7398\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9002 - val_loss: 0.8507 - val_accuracy: 0.7561\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9145 - val_loss: 0.8466 - val_accuracy: 0.7154\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9043 - val_loss: 0.9839 - val_accuracy: 0.7154\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9145 - val_loss: 0.8235 - val_accuracy: 0.7236\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9145 - val_loss: 0.9372 - val_accuracy: 0.6911\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9084 - val_loss: 0.7547 - val_accuracy: 0.7561\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9124 - val_loss: 0.9452 - val_accuracy: 0.7236\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9124 - val_loss: 0.8988 - val_accuracy: 0.6992\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9104 - val_loss: 0.8200 - val_accuracy: 0.7236\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9124 - val_loss: 1.1662 - val_accuracy: 0.7073\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9063 - val_loss: 1.0009 - val_accuracy: 0.6992\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9104 - val_loss: 0.9336 - val_accuracy: 0.6992\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9104 - val_loss: 0.9676 - val_accuracy: 0.7073\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9165 - val_loss: 0.9203 - val_accuracy: 0.7154\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9022 - val_loss: 0.8977 - val_accuracy: 0.6992\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9104 - val_loss: 0.9677 - val_accuracy: 0.7236\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9145 - val_loss: 0.9235 - val_accuracy: 0.6911\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9084 - val_loss: 0.8326 - val_accuracy: 0.7398\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9287 - val_loss: 0.9377 - val_accuracy: 0.7480\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9165 - val_loss: 0.8490 - val_accuracy: 0.7236\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9226 - val_loss: 0.8887 - val_accuracy: 0.6992\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9206 - val_loss: 0.8907 - val_accuracy: 0.7154\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9165 - val_loss: 0.8347 - val_accuracy: 0.7398\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.8941 - val_loss: 0.8716 - val_accuracy: 0.7236\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9063 - val_loss: 0.9825 - val_accuracy: 0.7317\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9063 - val_loss: 0.8442 - val_accuracy: 0.7317\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9084 - val_loss: 0.8200 - val_accuracy: 0.7398\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9185 - val_loss: 0.8699 - val_accuracy: 0.7398\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9145 - val_loss: 0.8681 - val_accuracy: 0.7561\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9165 - val_loss: 0.8414 - val_accuracy: 0.7398\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9348 - val_loss: 0.9844 - val_accuracy: 0.7073\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9002 - val_loss: 0.9908 - val_accuracy: 0.7236\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8717 - val_loss: 0.8359 - val_accuracy: 0.7480\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.8982 - val_loss: 0.7393 - val_accuracy: 0.7642\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 0.8904 - val_accuracy: 0.7236\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9246 - val_loss: 0.8946 - val_accuracy: 0.7236\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9267 - val_loss: 0.8544 - val_accuracy: 0.7073\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9104 - val_loss: 0.8454 - val_accuracy: 0.7236\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9124 - val_loss: 0.8275 - val_accuracy: 0.7642\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9206 - val_loss: 0.8682 - val_accuracy: 0.7561\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9022 - val_loss: 0.9399 - val_accuracy: 0.7398\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9002 - val_loss: 1.0052 - val_accuracy: 0.7154\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9308 - val_loss: 0.8846 - val_accuracy: 0.7398\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.8982 - val_loss: 0.9501 - val_accuracy: 0.7073\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9145 - val_loss: 0.8017 - val_accuracy: 0.7317\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9145 - val_loss: 1.0307 - val_accuracy: 0.6829\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9267 - val_loss: 0.9984 - val_accuracy: 0.7073\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9348 - val_loss: 0.9497 - val_accuracy: 0.7236\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9287 - val_loss: 0.9395 - val_accuracy: 0.7154\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9185 - val_loss: 0.8491 - val_accuracy: 0.7317\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9185 - val_loss: 0.8680 - val_accuracy: 0.7236\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9226 - val_loss: 1.2191 - val_accuracy: 0.6748\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.8961 - val_loss: 1.0252 - val_accuracy: 0.6992\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9084 - val_loss: 0.8180 - val_accuracy: 0.7317\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9165 - val_loss: 0.9595 - val_accuracy: 0.7480\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9308 - val_loss: 1.0335 - val_accuracy: 0.6829\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9226 - val_loss: 0.8289 - val_accuracy: 0.7480\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9246 - val_loss: 0.9589 - val_accuracy: 0.7154\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9287 - val_loss: 0.9819 - val_accuracy: 0.6911\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9267 - val_loss: 0.8567 - val_accuracy: 0.7317\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9226 - val_loss: 0.8815 - val_accuracy: 0.7317\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9226 - val_loss: 0.8555 - val_accuracy: 0.7236\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9165 - val_loss: 0.8698 - val_accuracy: 0.7317\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9124 - val_loss: 1.1192 - val_accuracy: 0.6585\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9185 - val_loss: 0.8410 - val_accuracy: 0.7398\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9246 - val_loss: 0.9352 - val_accuracy: 0.7236\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9165 - val_loss: 0.8929 - val_accuracy: 0.7154\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9104 - val_loss: 0.9403 - val_accuracy: 0.6748\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9185 - val_loss: 0.8577 - val_accuracy: 0.7154\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9389 - val_loss: 0.8994 - val_accuracy: 0.7236\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9308 - val_loss: 0.9244 - val_accuracy: 0.7398\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9043 - val_loss: 0.9910 - val_accuracy: 0.6992\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9328 - val_loss: 0.8360 - val_accuracy: 0.7480\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9206 - val_loss: 0.9689 - val_accuracy: 0.7398\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9246 - val_loss: 1.1648 - val_accuracy: 0.6911\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9308 - val_loss: 0.9805 - val_accuracy: 0.6911\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9328 - val_loss: 0.8899 - val_accuracy: 0.7398\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9206 - val_loss: 0.8884 - val_accuracy: 0.7398\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9206 - val_loss: 1.0144 - val_accuracy: 0.7236\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9328 - val_loss: 0.8980 - val_accuracy: 0.7561\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9165 - val_loss: 0.9401 - val_accuracy: 0.7154\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9185 - val_loss: 0.9576 - val_accuracy: 0.7480\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9287 - val_loss: 1.0638 - val_accuracy: 0.7561\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9145 - val_loss: 1.0364 - val_accuracy: 0.6992\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9206 - val_loss: 0.9756 - val_accuracy: 0.7317\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9185 - val_loss: 1.0597 - val_accuracy: 0.6992\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9206 - val_loss: 0.9828 - val_accuracy: 0.7236\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9104 - val_loss: 0.9353 - val_accuracy: 0.7561\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9308 - val_loss: 1.0006 - val_accuracy: 0.7398\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9287 - val_loss: 1.1131 - val_accuracy: 0.7398\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9369 - val_loss: 1.0790 - val_accuracy: 0.7317\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9165 - val_loss: 0.8897 - val_accuracy: 0.7480\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9022 - val_loss: 0.9987 - val_accuracy: 0.7073\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9124 - val_loss: 0.9608 - val_accuracy: 0.7154\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9328 - val_loss: 1.0000 - val_accuracy: 0.7073\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9552 - val_loss: 1.1076 - val_accuracy: 0.7317\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.9084 - val_loss: 1.0628 - val_accuracy: 0.7154\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9287 - val_loss: 0.9590 - val_accuracy: 0.7154\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8615 - val_loss: 0.9176 - val_accuracy: 0.7398\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9226 - val_loss: 0.9311 - val_accuracy: 0.7236\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9369 - val_loss: 1.0728 - val_accuracy: 0.7073\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9328 - val_loss: 0.9281 - val_accuracy: 0.6992\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9348 - val_loss: 1.1240 - val_accuracy: 0.7236\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9328 - val_loss: 0.9098 - val_accuracy: 0.7073\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 1.0679 - val_accuracy: 0.7073\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9409 - val_loss: 1.0566 - val_accuracy: 0.7398\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9246 - val_loss: 0.9995 - val_accuracy: 0.7236\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9267 - val_loss: 1.0159 - val_accuracy: 0.7073\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9430 - val_loss: 1.0967 - val_accuracy: 0.7073\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9145 - val_loss: 0.9264 - val_accuracy: 0.7317\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9308 - val_loss: 1.1027 - val_accuracy: 0.6748\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9409 - val_loss: 0.9970 - val_accuracy: 0.7236\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9348 - val_loss: 1.0713 - val_accuracy: 0.6911\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9267 - val_loss: 1.0064 - val_accuracy: 0.7317\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9328 - val_loss: 1.1842 - val_accuracy: 0.7317\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9328 - val_loss: 1.1431 - val_accuracy: 0.6911\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9063 - val_loss: 1.0116 - val_accuracy: 0.7317\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9369 - val_loss: 0.9441 - val_accuracy: 0.7073\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9369 - val_loss: 0.9986 - val_accuracy: 0.7236\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9206 - val_loss: 0.9797 - val_accuracy: 0.7236\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9226 - val_loss: 1.1571 - val_accuracy: 0.7154\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9348 - val_loss: 1.0684 - val_accuracy: 0.7236\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9145 - val_loss: 1.1903 - val_accuracy: 0.7236\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9308 - val_loss: 0.9969 - val_accuracy: 0.7317\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8941 - val_loss: 0.8909 - val_accuracy: 0.7480\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9185 - val_loss: 0.9370 - val_accuracy: 0.7154\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9206 - val_loss: 1.0409 - val_accuracy: 0.7073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "653464d8-ff16-4693-f561-726baff04e92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "e396b2d0-1466-4671-d504-3fdfbaf3c03b"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "eed97bc1-d1cd-4fa5-f3e2-518eb00ee095"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5125998 , 0.48740014]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "2676fb72-cbd9-47a7-d037-de57ebaaf57a"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}